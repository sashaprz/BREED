data:
  root_path: /workspace/inorganic_SEEs-1/generator/CDVAE/data/mp_20
  prop: formation_energy
  num_targets: 1
  niggli: true
  primitive: false
  graph_method: crystalnn
  lattice_scale_method: scale_length
  preprocess_workers: 30
  readout: mean
  max_atoms: 20
  otf_graph: false
  eval_model_name: enhanced_mp20
  train_max_epochs: 300
  early_stopping_patience: 10
  teacher_forcing_max_epoch: 10
  use_cache: true
  cache_dir: enhanced_cache
  datamodule:
    _target_: cdvae.pl_data.datamodule.CrystDataModule
    datasets:
      train:
        _target_: cdvae.pl_data.dataset.CrystDataset
        name: Enhanced Formation energy train
        path: ${data.root_path}/train.pkl
        prop: ${data.prop}
        niggli: ${data.niggli}
        primitive: ${data.primitive}
        graph_method: ${data.graph_method}
        lattice_scale_method: ${data.lattice_scale_method}
        preprocess_workers: ${data.preprocess_workers}
        use_cache: ${data.use_cache}
      val:
      - _target_: cdvae.pl_data.dataset.CrystDataset
        name: Enhanced Formation energy val
        path: ${data.root_path}/val.pkl
        prop: ${data.prop}
        niggli: ${data.niggli}
        primitive: ${data.primitive}
        graph_method: ${data.graph_method}
        lattice_scale_method: ${data.lattice_scale_method}
        preprocess_workers: ${data.preprocess_workers}
        use_cache: ${data.use_cache}
      test:
      - _target_: cdvae.pl_data.dataset.CrystDataset
        name: Enhanced Formation energy test
        path: ${data.root_path}/test.pkl
        prop: ${data.prop}
        niggli: ${data.niggli}
        primitive: ${data.primitive}
        graph_method: ${data.graph_method}
        lattice_scale_method: ${data.lattice_scale_method}
        preprocess_workers: ${data.preprocess_workers}
        use_cache: ${data.use_cache}
    num_workers:
      train: 4
      val: 4
      test: 4
    batch_size:
      train: 128
      val: 256
      test: 256
logging:
  val_check_interval: 5
  progress_bar_refresh_rate: 20
  enable_progress_bar: true
  wandb:
    name: ${expname}
    project: crystal_generation_mit
    entity: null
    log_model: true
    mode: online
    group: ${expname}
  wandb_watch:
    log: all
    log_freq: 500
  lr_monitor:
    logging_interval: step
    log_momentum: false
model:
  encoder:
    _target_: cdvae.pl_modules.gnn.DimeNetPlusPlusWrap
    num_targets: ${data.num_targets}
    hidden_channels: 128
    num_blocks: 4
    int_emb_size: 64
    basis_emb_size: 8
    out_emb_channels: 256
    num_spherical: 7
    num_radial: 6
    otf_graph: ${data.otf_graph}
    cutoff: 7.0
    max_num_neighbors: 20
    envelope_exponent: 5
    num_before_skip: 1
    num_after_skip: 2
    num_output_layers: 3
    readout: ${data.readout}
  decoder:
    _target_: cdvae.pl_modules.decoder.GemNetTDecoder
    hidden_dim: 128
    latent_dim: ${model.latent_dim}
    max_neighbors: ${model.max_neighbors}
    radius: ${model.radius}
    scale_file: /workspace/inorganic_SEEs-1/generator/CDVAE/cdvae/pl_modules/gemnet/gemnet-dT.json
  _target_: cdvae.pl_modules.enhanced_model.EnhancedCDVAE
  hidden_dim: 256
  latent_dim: 256
  fc_num_layers: 2
  max_atoms: ${data.max_atoms}
  cost_natom: 2.0
  cost_natom_enhanced: 3.0
  cost_coord: 10.0
  cost_type: 1.0
  cost_lattice: 10.0
  cost_composition: 1.5
  cost_edge: 10.0
  cost_property: 1.0
  beta: 0.01
  beta_start: 0.0
  beta_end: 0.01
  beta_warmup_epochs: 15
  beta_schedule: cosine
  kld_capacity: 0.0
  transformer_layers: 3
  attention_heads: 8
  dropout_rate: 0.1
  teacher_forcing_lattice: true
  teacher_forcing_max_epoch: ${data.teacher_forcing_max_epoch}
  max_neighbors: 20
  radius: 7.0
  sigma_begin: 10.0
  sigma_end: 0.01
  type_sigma_begin: 5.0
  type_sigma_end: 0.01
  num_noise_level: 50
  predict_property: false
optim:
  use_lr_scheduler: true
  optimizer:
    _target_: torch.optim.AdamW
    lr: 0.0002
    weight_decay: 0.0001
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    T_0: 50
    T_mult: 2
    eta_min: 1.0e-06
train:
  deterministic: false
  random_seed: 42
  monitor_metric: val_loss
  monitor_metric_mode: min
  early_stopping:
    patience: 15
    verbose: true
  model_checkpoints:
    save_top_k: 3
    verbose: true
  pl_trainer:
    accelerator: gpu
    devices: 1
    precision: 16-mixed
    max_epochs: 300
    gradient_clip_val: 1.0
    accumulate_grad_batches: 2
    fast_dev_run: false
    enable_checkpointing: true
    enable_progress_bar: true
    enable_model_summary: true
    check_val_every_n_epoch: 1
    val_check_interval: 1.0
    log_every_n_steps: 50
    benchmark: true
expname: enhanced_cdvae
core:
  version: 0.1.0
  tags:
  - ${now:%Y-%m-%d}
  - enhanced
  - cached
  - transformer
