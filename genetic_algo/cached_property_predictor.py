#!/usr/bin/env python3
"""
Cached Property Predictor - EXACT same logic as property_prediction_script.py but with cached models
This eliminates the model reloading bottleneck while maintaining identical prediction behavior.
"""

import os
import sys
import torch
import pandas as pd
import numpy as np
from typing import Dict, Any, Optional
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Add parent directory to path so we can import from env
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import exactly the same modules as property_prediction_script.py
from env.sei_predictor import SEIPredictor
from env.cei_predictor import CEIPredictor
from env.property_predictions.cgcnn_pretrained.cgcnn.model import CrystalGraphConvNet
from env.property_predictions.cgcnn_pretrained.cgcnn.data import CIFData, collate_pool
from env.property_predictions.main import Normalizer

# Import bandgap correction from fully_optimized_predictor (same logic)
from genetic_algo.fully_optimized_predictor import apply_ml_bandgap_correction, BANDGAP_CORRECTION_AVAILABLE, CORRECTION_METHOD

class CachedPropertyPredictor:
    """
    EXACT same prediction logic as property_prediction_script.py but with cached models
    This eliminates model reloading while maintaining identical behavior
    """
    
    def __init__(self):
        # Configuration paths - EXACT same as property_prediction_script.py
        self.dataset_root = r"C:\Users\Sasha\repos\RL-electrolyte-design\env\property_predictions\CIF_OBELiX"
        self.bandgap_model_path = r"C:\Users\Sasha\repos\RL-electrolyte-design\env\property_predictions\cgcnn_pretrained\band-gap.pth.tar"
        self.bulk_model_path = r"C:\Users\Sasha\repos\RL-electrolyte-design\env\property_predictions\cgcnn_pretrained\bulk-moduli.pth.tar"
        self.finetuned_model_path = r"C:\Users\Sasha\repos\RL-electrolyte-design\env\checkpoint.pth.tar"
        
        # Cached models and predictors - loaded ONCE
        self._sei_predictor = None
        self._cei_predictor = None
        self._bandgap_model = None
        self._bulk_model = None
        self._finetuned_model = None
        self._finetuned_normalizer = None
        self._device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Dataset cache
        self._dataset = None
        self._cif_filenames = None
        
        print(f"CachedPropertyPredictor initialized - will cache models to eliminate reloading")
    
    def _load_dataset_once(self):
        """Load dataset information once and cache it"""
        if self._dataset is None or self._cif_filenames is None:
            print("Loading dataset information (one-time setup)...")
            cifs_folder = os.path.join(self.dataset_root, "cifs")
            self._dataset = CIFData(cifs_folder)
            
            # Read CIF filenames
            id_prop_path = os.path.join(cifs_folder, "id_prop.csv")
            id_prop_df = pd.read_csv(id_prop_path)
            cif_ids = id_prop_df.iloc[:, 0].tolist()
            self._cif_filenames = [cid + ".cif" for cid in cif_ids]
            print(f"Dataset loaded with {len(self._cif_filenames)} CIF files")
        
        return self._dataset, self._cif_filenames
    
    def _load_cgcnn_model_once(self, model_path: str, model_name: str):
        """Load a CGCNN model ONCE with proper architecture from checkpoint"""
        print(f"ðŸ”„ Loading {model_name} model (ONE TIME ONLY)...")
        
        # Ensure dataset is loaded first
        self._load_dataset_once()
        
        checkpoint = torch.load(model_path, map_location=self._device)
        
        # Get model architecture from sample
        sample = [self._dataset[0]]
        input_data, _, _ = collate_pool(sample)
        
        orig_atom_fea_len = input_data[0].shape[-1]
        nbr_fea_len = input_data[1].shape[-1]
        
        # Use standard architecture (same as property_prediction_script.py)
        atom_fea_len = 64
        n_conv = 3
        h_fea_len = 128
        n_h = 1
        
        model = CrystalGraphConvNet(
            orig_atom_fea_len=orig_atom_fea_len,
            nbr_fea_len=nbr_fea_len,
            atom_fea_len=atom_fea_len,
            n_conv=n_conv,
            h_fea_len=h_fea_len,
            n_h=n_h,
            classification=False
        ).to(self._device)
        
        model.load_state_dict(checkpoint['state_dict'])
        model.eval()
        
        print(f"âœ… {model_name} model loaded and cached successfully!")
        return model, checkpoint
    
    def get_sei_predictor(self):
        """Get SEI predictor (loaded once)"""
        if self._sei_predictor is None:
            print("ðŸ”„ Loading SEI predictor (ONE TIME ONLY)...")
            self._sei_predictor = SEIPredictor()
            print("âœ… SEI predictor loaded and cached!")
        return self._sei_predictor
    
    def get_cei_predictor(self):
        """Get CEI predictor (loaded once)"""
        if self._cei_predictor is None:
            print("ðŸ”„ Loading CEI predictor (ONE TIME ONLY)...")
            self._cei_predictor = CEIPredictor()
            print("âœ… CEI predictor loaded and cached!")
        return self._cei_predictor
    
    def get_bandgap_model(self):
        """Get bandgap model (loaded once)"""
        if self._bandgap_model is None:
            self._bandgap_model, _ = self._load_cgcnn_model_once(
                self.bandgap_model_path, "Bandgap"
            )
        return self._bandgap_model
    
    def get_bulk_model(self):
        """Get bulk modulus model (loaded once)"""
        if self._bulk_model is None:
            self._bulk_model, _ = self._load_cgcnn_model_once(
                self.bulk_model_path, "Bulk Modulus"
            )
        return self._bulk_model
    
    def get_finetuned_model(self):
        """Get finetuned ionic conductivity model (loaded once)"""
        if self._finetuned_model is None:
            self._finetuned_model, checkpoint = self._load_cgcnn_model_once(
                self.finetuned_model_path, "Ionic Conductivity"
            )
            
            # Load normalizer if available
            if 'normalizer' in checkpoint:
                self._finetuned_normalizer = Normalizer(torch.tensor([0.0]))
                self._finetuned_normalizer.load_state_dict(checkpoint['normalizer'])
                print("âœ… Normalizer loaded for ionic conductivity model")
        
        return self._finetuned_model, self._finetuned_normalizer
    
    def predict_cgcnn_property_cached(self, model, cif_file_path: str, normalizer=None):
        """
        Predict property using cached CGCNN model - EXACT same logic as property_prediction_script.py
        but without model reloading
        """
        try:
            # Create temporary directory structure that CIFData expects
            import tempfile
            import shutil
            
            with tempfile.TemporaryDirectory() as temp_dir:
                # Copy CIF file to temp directory with simple name
                temp_cif_name = "temp_structure"
                temp_cif_path = os.path.join(temp_dir, temp_cif_name + ".cif")
                shutil.copy2(cif_file_path, temp_cif_path)
                
                # Create id_prop.csv with dummy target (we only care about prediction)
                id_prop_path = os.path.join(temp_dir, "id_prop.csv")
                with open(id_prop_path, 'w') as f:
                    f.write(f"{temp_cif_name},0.0\n")  # dummy target value
                
                # Copy atom_init.json from the main dataset
                atom_init_src = os.path.join(self.dataset_root, "cifs", "atom_init.json")
                atom_init_dst = os.path.join(temp_dir, "atom_init.json")
                shutil.copy2(atom_init_src, atom_init_dst)
                
                # Create dataset using the standard CIFData interface
                temp_dataset = CIFData(temp_dir)
                
                # Prepare sample
                sample = [temp_dataset[0]]
                input_data, targets, cif_ids_result = collate_pool(sample)
                
                input_vars = (
                    input_data[0].to(self._device),
                    input_data[1].to(self._device),
                    input_data[2].to(self._device),
                    input_data[3],  # crystal_atom_idx (stays on CPU)
                )
                
                with torch.no_grad():
                    output = model(*input_vars)
                    pred = output.cpu().numpy().flatten()[0]
                
                # Denormalize if normalizer available
                if normalizer is not None:
                    pred_tensor = torch.tensor([pred])
                    pred = normalizer.denorm(pred_tensor).item()
                
                return pred
            
        except Exception as e:
            print(f"    CGCNN prediction error: {e}")
            return 0.0
    
    def run_sei_prediction_cached(self, cif_file_path: str):
        """Run SEI prediction using cached predictor"""
        predictor = self.get_sei_predictor()
        results = predictor.predict_from_cif(cif_file_path)
        return results
    
    def run_cei_prediction_cached(self, cif_file_path: str):
        """Run CEI prediction using cached predictor"""
        predictor = self.get_cei_predictor()
        results = predictor.predict_from_cif(cif_file_path)
        return results
    
    def extract_composition_from_cif(self, cif_file_path: str) -> str:
        """Extract composition from CIF file exactly as in property_prediction_script.py"""
        try:
            with open(cif_file_path, 'r') as f:
                lines = f.readlines()
            
            # Look for data_ line which often contains composition info
            for line in lines:
                if line.startswith('data_'):
                    composition = line.replace('data_', '').strip()
                    if composition:
                        return composition
            
            # Fallback: use filename
            return os.path.splitext(os.path.basename(cif_file_path))[0]
        except:
            return os.path.splitext(os.path.basename(cif_file_path))[0]
    
    def estimate_ionic_conductivity_from_composition(self, composition_str: str) -> float:
        """
        Estimate ionic conductivity based on composition using empirical rules
        EXACT same logic as property_prediction_script.py
        """
        import re
        import random
        
        # Parse composition string to extract elements and counts
        elements = {}
        
        # Try to extract elements from composition string
        pattern = r'([A-Z][a-z]?)(\d*)'
        matches = re.findall(pattern, composition_str)
        
        for element, count in matches:
            count = int(count) if count else 1
            elements[element] = count
        
        # Base conductivity estimation
        base_conductivity = 1e-8  # Default low conductivity
        
        # Li content factor (most important for solid electrolytes)
        if 'Li' in elements:
            li_content = elements['Li']
            total_atoms = sum(elements.values())
            li_fraction = li_content / total_atoms if total_atoms > 0 else 0
            
            # Higher Li content generally means higher conductivity
            if li_fraction > 0.3:  # High Li content
                base_conductivity *= 1000  # 1e-5
            elif li_fraction > 0.1:  # Medium Li content
                base_conductivity *= 100   # 1e-6
            else:  # Low Li content
                base_conductivity *= 10    # 1e-7
        
        # Favorable elements for ionic conductivity
        favorable_elements = ['P', 'S', 'O', 'F', 'Cl']
        favorable_count = sum(1 for elem in favorable_elements if elem in elements)
        
        if favorable_count >= 2:
            base_conductivity *= 10  # Multiple favorable elements
        elif favorable_count == 1:
            base_conductivity *= 3   # One favorable element
        
        # Specific structure types (based on common solid electrolytes)
        if 'P' in elements and 'S' in elements:  # Sulfide-based (like argyrodites)
            base_conductivity *= 100
        elif 'Ti' in elements and 'P' in elements:  # NASICON-type
            base_conductivity *= 50
        elif 'La' in elements and 'Zr' in elements:  # Garnet-type
            base_conductivity *= 20
        elif 'Al' in elements and 'Ge' in elements:  # LAGP-type
            base_conductivity *= 30
        
        # Add some randomness to avoid identical values
        random_factor = random.uniform(0.5, 2.0)
        final_conductivity = base_conductivity * random_factor
        
        # Ensure reasonable bounds for solid electrolytes
        final_conductivity = max(1e-12, min(1e-2, final_conductivity))
        
        return final_conductivity
    
    def predict_single_cif(self, cif_file_path: str, verbose: bool = False) -> Dict[str, Any]:
        """
        Run all predictions with EXACT same logic as property_prediction_script.py
        but using cached models to eliminate reloading bottleneck
        """
        
        results = {
            "composition": self.extract_composition_from_cif(cif_file_path),
            "bandgap": 0.0,
            "sei_score": 0.0,
            "cei_score": 0.0,
            "ionic_conductivity": 0.0,
            "bulk_modulus": 0.0,
            "prediction_status": {
                "sei": "failed",
                "cei": "failed", 
                "bandgap": "failed",
                "bulk_modulus": "failed",
                "ionic_conductivity": "failed"
            }
        }
        
        if verbose:
            print(f"Processing CIF: {os.path.basename(cif_file_path)}")
        
        # Run SEI Prediction (exactly as in property_prediction_script.py)
        try:
            sei_results = self.run_sei_prediction_cached(cif_file_path)
            if sei_results is not None and 'sei_score' in sei_results:
                results["sei_score"] = float(sei_results['sei_score'])
                results["prediction_status"]["sei"] = "success"
                if verbose:
                    print(f"  SEI Score: {results['sei_score']:.3f}")
            else:
                if verbose:
                    print("  SEI prediction failed or no score returned")
        except Exception as e:
            if verbose:
                print(f"  SEI prediction failed: {e}")
        
        # CEI Prediction (exactly as in property_prediction_script.py)
        try:
            cei_results = self.run_cei_prediction_cached(cif_file_path)
            if cei_results is not None and 'cei_score' in cei_results:
                results["cei_score"] = float(cei_results['cei_score'])
                results["prediction_status"]["cei"] = "success"
                if verbose:
                    print(f"  CEI Score: {results['cei_score']:.3f}")
            else:
                if verbose:
                    print("  CEI prediction failed or no score returned")
        except Exception as e:
            if verbose:
                print(f"  CEI prediction failed: {e}")
        
        # Bandgap Prediction (exactly as in property_prediction_script.py + bandgap correction)
        try:
            bandgap_model = self.get_bandgap_model()
            raw_pbe_bandgap = self.predict_cgcnn_property_cached(bandgap_model, cif_file_path)
            
            if raw_pbe_bandgap is not None:
                # Apply bandgap correction (EXACT same logic as property_prediction_script.py)
                if BANDGAP_CORRECTION_AVAILABLE and raw_pbe_bandgap != 0.0:
                    composition_str = results["composition"]
                    corrected_bandgap = apply_ml_bandgap_correction(raw_pbe_bandgap, composition_str)
                    
                    results["bandgap"] = float(corrected_bandgap)
                    results["bandgap_raw_pbe"] = float(raw_pbe_bandgap)
                    results["bandgap_correction_applied"] = True
                    results["correction_method"] = CORRECTION_METHOD
                else:
                    results["bandgap"] = raw_pbe_bandgap
                    results["bandgap_correction_applied"] = False
                    results["correction_method"] = "none"
                
                results["prediction_status"]["bandgap"] = "success"
                if verbose:
                    if results["bandgap_correction_applied"]:
                        print(f"  Bandgap (PBE): {raw_pbe_bandgap:.3f} eV")
                        print(f"  Bandgap (HSE-corrected): {results['bandgap']:.3f} eV")
                    else:
                        print(f"  Bandgap: {results['bandgap']:.3f} eV")
            else:
                if verbose:
                    print("  Bandgap prediction failed or no predictions returned")
        except Exception as e:
            if verbose:
                print(f"  Bandgap prediction failed: {e}")
        
        # Bulk Modulus Prediction (exactly as in property_prediction_script.py)
        try:
            bulk_model = self.get_bulk_model()
            bulk_pred = self.predict_cgcnn_property_cached(bulk_model, cif_file_path)
            
            if bulk_pred is not None:
                results["bulk_modulus"] = float(bulk_pred)
                results["prediction_status"]["bulk_modulus"] = "success"
                if verbose:
                    print(f"  Bulk Modulus: {results['bulk_modulus']:.1f} GPa")
            else:
                if verbose:
                    print("  Bulk modulus prediction failed or no predictions returned")
        except Exception as e:
            if verbose:
                print(f"  Bulk modulus prediction failed: {e}")
        
        # Ionic Conductivity Prediction (with improved fallback handling)
        try:
            finetuned_model, normalizer = self.get_finetuned_model()
            ic_pred = self.predict_cgcnn_property_cached(finetuned_model, cif_file_path, normalizer)
            
            if ic_pred is not None and ic_pred > 0 and ic_pred < 1.0:  # Reasonable range
                results["ionic_conductivity"] = float(ic_pred)
                results["prediction_status"]["ionic_conductivity"] = "success"
                if verbose:
                    print(f"  Ionic Conductivity: {results['ionic_conductivity']:.2e} S/cm")
            else:
                # Use composition-based estimation as fallback
                results["ionic_conductivity"] = self.estimate_ionic_conductivity_from_composition(results["composition"])
                results["prediction_status"]["ionic_conductivity"] = "estimated"
                if verbose:
                    print(f"  Ionic conductivity prediction failed, using estimation: {results['ionic_conductivity']:.2e} S/cm")
        except Exception as e:
            # Use composition-based estimation as fallback
            results["ionic_conductivity"] = self.estimate_ionic_conductivity_from_composition(results["composition"])
            results["prediction_status"]["ionic_conductivity"] = "estimated"
            if verbose:
                print(f"  Ionic conductivity prediction failed ({e}), using estimation: {results['ionic_conductivity']:.2e} S/cm")
        
        return results


# Global instance for caching
_global_cached_predictor = None

def get_cached_predictor():
    """Get the global cached predictor instance"""
    global _global_cached_predictor
    if _global_cached_predictor is None:
        _global_cached_predictor = CachedPropertyPredictor()
    return _global_cached_predictor

def predict_single_cif_cached(cif_file_path: str, verbose: bool = False) -> Dict[str, Any]:
    """Cached prediction function - models loaded ONCE and cached forever"""
    predictor = get_cached_predictor()
    return predictor.predict_single_cif(cif_file_path, verbose)

if __name__ == "__main__":
    print("ðŸ”¬ CACHED PROPERTY PREDICTOR TEST")
    print("=" * 50)
    print("Same logic as property_prediction_script.py but with cached models")
    print("This eliminates model reloading for massive speed improvement")